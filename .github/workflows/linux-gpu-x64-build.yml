name: "Linux GPU x64 Build"
on: [ workflow_dispatch, pull_request ]

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

env:
  ort_dir: "onnxruntime-linux-x64-gpu-1.17.1"
  ort_zip: "onnxruntime-linux-x64-gpu-1.17.1.tgz"
  ort_url: "https://github.com/microsoft/onnxruntime/releases/download/v1.17.1/onnxruntime-linux-x64-gpu-1.17.1.tgz"
  ORT_NIGHTLY_REST_API: "https://feeds.dev.azure.com/aiinfra/PublicPackages/_apis/packaging/Feeds/ORT-Nightly/packages?packageNameQuery=Microsoft.ML.OnnxRuntime.Gpu.Linux&api-version=6.0-preview.1"
  ORT_NIGHTLY_PACKAGE_NAME: "Microsoft.ML.OnnxRuntime.Gpu.Linux"

jobs:
  linux-gpu-x64-build:
    runs-on: [ "self-hosted", "1ES.Pool=onnxruntime-genai-Ubuntu2004-T4" ]
    steps:
      - name: Checkout OnnxRuntime GenAI repo
        uses: actions/checkout@v4
        with:
          submodules: true
      - name: Install jq and nuget
        run: |
          sudo apt-get install jq nuget

      - name: Get the Latest OnnxRuntime Nightly Version
        run: |
          ORT_NIGHTLY_VERSION=$(curl -s "${{ env.ORT_NIGHTLY_REST_API }}" | jq -r '.value[0].versions[0].normalizedVersion')
          echo "$ORT_NIGHTLY_VERSION" 
          echo "ORT_NIGHTLY_VERSION=$ORT_NIGHTLY_VERSION" >> $GITHUB_ENV
      - name: Search Nuget Source
        run: |
          nuget search "${{ env.ORT_NIGHTLY_PACKAGE_NAME }}" -Source "${{ env.ORT_NIGHTLY_SOURCE }}" -Verbosity detailed

      - name: Download OnnxRuntime Nightly
        run: |
          nuget install "${{ env.ORT_NIGHTLY_PACKAGE_NAME }}" -version "${{ env.ORT_NIGHTLY_VERSION }}" -x -Source "${{ env.ORT_NIGHTLY_SOURCE }}"

      - name: Extra OnnxRuntime library and header files
        run: |
          mkdir -p ort/lib
          mv ${{ env.ORT_NIGHTLY_PACKAGE_NAME }}/build/native/include ort/
          mv ${{ env.ORT_NIGHTLY_PACKAGE_NAME }}/runtimes/linux-x64/native/* ort/lib/


      - name: Download Docker Image
        run: |
          set -e -x
          az login --identity --username 63b63039-6328-442f-954b-5a64d124e5b4
          az acr login --name onnxruntimebuildcache --subscription 00c06639-6ee4-454e-8058-8d8b1703bd87
          python3 tools/ci_build/get_docker_image.py --dockerfile tools/ci_build/github/linux/docker/inference/x64/default/gpu/Dockerfile \
            --context tools/ci_build/github/linux/docker/inference/x64/default/gpu \
            --docker-build-args "--build-arg BUILD_UID=$( id -u )" \
            --container-registry onnxruntimebuildcache \
            --repository ort_genai_linux_gpu_gha

      - name: Print Docker Image Environment Variables
        run: |
          echo "Printing docker image environment variables"
          docker run --rm ort_genai_linux_gpu_gha env

      - name: Build with Cmake in Docker
        run: |
          echo "Running docker image ort_genai_linux_gpu_gha"
          docker run \
            --gpus all \
            --rm \
            --volume $GITHUB_WORKSPACE:/onnxruntime_src \
            -w /onnxruntime_src ort_genai_linux_gpu_gha bash -c "echo $PATH && /usr/bin/cmake -DCMAKE_CUDA_ARCHITECTURES=86 --preset linux_gcc_cuda_release && /usr/bin/cmake --build --preset linux_gcc_cuda_release"
      
      - name: Install the onnxruntime-genai Python wheel and run Python tests
        run: |
          echo "Installing the onnxruntime-genai Python wheel and running the Python tests"
          docker run \
            --gpus all \
            --rm \
            --volume $GITHUB_WORKSPACE:/onnxruntime_src \
            -w /onnxruntime_src ort_genai_linux_gpu_gha bash -c "python3 -m pip install /onnxruntime_src/build/cuda/wheel/onnxruntime_genai*.whl --user && python3 -m pip install -r test/python/requirements.txt --user && python3 test/python/test_onnxruntime_genai.py --cwd test/python --test_models test/test_models"

      - name: Docker -- Run tests
        run: |
          echo "Running docker image ort_genai_linux_gpu_gha"
          docker run \
            --gpus all \
            --rm \
            --volume $GITHUB_WORKSPACE:/onnxruntime_src \
            -w /onnxruntime_src ort_genai_linux_gpu_gha bash -c "/onnxruntime_src/build/cuda/test/unit_tests"
