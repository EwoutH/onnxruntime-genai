name: "Linux CPU x64 Build"
on: [ workflow_dispatch, pull_request ]
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true
env:
  ORT_NIGHTLY_REST_API: "https://feeds.dev.azure.com/aiinfra/PublicPackages/_apis/packaging/Feeds/ORT-Nightly/packages?packageNameQuery=Microsoft.ML.OnnxRuntime&api-version=6.0-preview.1"
  ORT_NIGHTLY_PACKAGE_NAME: "Microsoft.ML.OnnxRuntime"
  ORT_NIGHTLY_PACKAGE_NAME_L: "microsoft.ml.onnxruntime"
  ORT_NIGHTLY_SOURCE: "https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ORT-Nightly/nuget/v3/index.json"
jobs:
  linux_cpu_x64:
    runs-on: [ "self-hosted", "1ES.Pool=onnxruntime-genai-Ubuntu2204-AMD-CPU" ]
    steps:
      - name: Checkout OnnxRuntime GenAI repo
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install jq and dotnet
        run: |
          wget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb
          sudo dpkg -i packages-microsoft-prod.deb
          rm packages-microsoft-prod.deb
          sudo apt-get update && sudo apt-get install -y dotnet-sdk-8.0 jq

      - name: Get the Latest OnnxRuntime Nightly Version
        run: |
          ORT_NIGHTLY_VERSION=$(curl -s "${{ env.ORT_NIGHTLY_REST_API }}" | jq -r '.value[0].versions[0].normalizedVersion')
          echo "$ORT_NIGHTLY_VERSION" 
          echo "ORT_NIGHTLY_VERSION=$ORT_NIGHTLY_VERSION" >> $GITHUB_ENV

      - name: Download OnnxRuntime Nightly
        run: |
          dotnet add package "${{ env.ORT_NIGHTLY_PACKAGE_NAME }}" --version "${{ env.ORT_NIGHTLY_VERSION }}" --source "${{ env.ORT_NIGHTLY_SOURCE }}" --package-directory .
        continue-on-error: true
      - name: list files
        shell: bash
        run: |
          ls -l
      - name: Extra OnnxRuntime library and header files
        run: |
          mkdir -p ort/lib
          mv ${{ env.ORT_NIGHTLY_PACKAGE_NAME_L }}/build/native/include ort/
          mv ${{ env.ORT_NIGHTLY_PACKAGE_NAME_L }}/runtimes/linux-x64/native/* ort/lib/

      - name: Build with CMake and GCC
        run: |
          set -e -x
          rm -rf build
          cmake --preset linux_gcc_cpu_release
          cmake --build --preset linux_gcc_cpu_release

      - name: Install the python wheel and test dependencies
        run: |
          python3 -m pip install build/cpu/wheel/onnxruntime_genai*.whl
          python3 -m pip install -r test/python/requirements-nightly-cpu.txt --user

      - name: Get HuggingFace Token
        run: |
          az login --identity --username 63b63039-6328-442f-954b-5a64d124e5b4
          HF_TOKEN=$(az keyvault secret show --vault-name anubissvcsecret --name ANUBIS-HUGGINGFACE-TOKEN --query value)
          echo "::add-mask::$HF_TOKEN"
          echo "HF_TOKEN=$HF_TOKEN" >> $GITHUB_ENV

      # This will also download all the test models to the test/test_models directory
      # These models are used by the python tests as well as C#, C++ and others.
      - name: Run the python tests
        run: |
          python3 test/python/test_onnxruntime_genai.py --cwd test/python --test_models test/test_models

      - name: Verify Build Artifacts
        if: always()
        continue-on-error: true
        run: |
          ls -l ${{ github.workspace }}/build/cpu

      - name: Run tests
        run: |
          set -e -x
          ./build/cpu/test/unit_tests
